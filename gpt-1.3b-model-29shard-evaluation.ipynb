{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12088.995613,
      "end_time": "2021-08-23T21:56:38.698241",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-08-23T18:35:09.702628",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "name": "gpt-1-3b-model-29shard-training.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.007519,
          "end_time": "2021-08-23T18:35:16.370340",
          "exception": false,
          "start_time": "2021-08-23T18:35:16.362821",
          "status": "completed"
        },
        "tags": [],
        "id": "8261f526"
      },
      "source": [
        "# About This Notebook\n",
        "* This notebook evaluates the number of tokens generated by the model EleutherAI/gpt-neo-1.3B with The Pile data\n",
        "* The Evaluation is done by the following methodology\n",
        "\n",
        "* Select documents within THE PILE 29 dataset with more than or equal to 40 tokens, replace the skipped logits with np.nan\n",
        "* Utilize the first 20 tokens of each document as input to the model and use the subsequent 20 tokens to calculate the number of correctly predicted tokens\n",
        "* Correctly predicted tokens are found by comparing the tokens in range 20..40 of the input document with the tokens in range 20--40 of generated document\n",
        "* This data is stored in the array acc and saved in the file 'data29.pkl'\n",
        "*The input to this dataset was a [kaggle dataset](https://www.kaggle.com/usaiprashanth/the-pile-generator) with output in the following [kaggle dataset](https://www.kaggle.com/usaiprashanth/gptmodel-outputs)\n",
        "* The following notebook is from a [kaggle notebook](https://www.kaggle.com/usaiprashanth/gpt-1-3b-model?scriptVersionId=72840198)"
      ],
      "id": "8261f526"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T18:35:16.395577Z",
          "iopub.status.busy": "2021-08-23T18:35:16.394870Z",
          "iopub.status.idle": "2021-08-23T18:35:32.107950Z",
          "shell.execute_reply": "2021-08-23T18:35:32.107306Z",
          "shell.execute_reply.started": "2021-08-23T18:24:14.191462Z"
        },
        "papermill": {
          "duration": 15.73092,
          "end_time": "2021-08-23T18:35:32.108111",
          "exception": false,
          "start_time": "2021-08-23T18:35:16.377191",
          "status": "completed"
        },
        "tags": [],
        "id": "c293ab7f",
        "outputId": "1e8dc3b6-b7ee-4d9b-c59c-909b213f107f"
      },
      "source": [
        "!pip install lm-dataformat #Library for easy retrieval of The pile data from jsonl.zstd files\n",
        "!pip install transformers #Library for easy interaction with gpt-neo-1.3B model"
      ],
      "id": "c293ab7f",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lm-dataformat\r\n",
            "  Downloading lm_dataformat-0.0.19-py3-none-any.whl (5.4 kB)\r\n",
            "Collecting jsonlines\r\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\r\n",
            "Requirement already satisfied: ujson in /opt/conda/lib/python3.7/site-packages (from lm-dataformat) (4.0.2)\r\n",
            "Collecting zstandard\r\n",
            "  Downloading zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\r\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 892 kB/s \r\n",
            "\u001b[?25hInstalling collected packages: zstandard, jsonlines, lm-dataformat\r\n",
            "Successfully installed jsonlines-2.0.0 lm-dataformat-0.0.19 zstandard-0.15.2\r\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.6.1)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\r\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.8)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.61.1)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\r\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\r\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\r\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\r\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011681,
          "end_time": "2021-08-23T18:35:32.132558",
          "exception": false,
          "start_time": "2021-08-23T18:35:32.120877",
          "status": "completed"
        },
        "tags": [],
        "id": "a1be7446"
      },
      "source": [
        "* Creating the @param model using Huggingface api"
      ],
      "id": "a1be7446"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T18:35:32.161715Z",
          "iopub.status.busy": "2021-08-23T18:35:32.160584Z",
          "iopub.status.idle": "2021-08-23T18:41:54.471209Z",
          "shell.execute_reply": "2021-08-23T18:41:54.470669Z",
          "shell.execute_reply.started": "2021-08-23T18:24:29.052898Z"
        },
        "papermill": {
          "duration": 382.327075,
          "end_time": "2021-08-23T18:41:54.471339",
          "exception": false,
          "start_time": "2021-08-23T18:35:32.144264",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "d56252df61e94f8b8c2cd09f25586ed7",
            "f5d8131470794f49a18e6a2483c9aedb",
            "24caf0f25e724ab5874901575a9dff4f",
            "4450dea65a1a407db95aa762eb3ab97d",
            "0f668f3ea91b4a82ac1167c554f4554f",
            "461ae64db411441da7f731bb4522b75f"
          ]
        },
        "id": "6ad3942a",
        "outputId": "a1a0a7bf-a9bc-4b7c-b8fb-a4036feb596d"
      },
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "id": "6ad3942a",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d56252df61e94f8b8c2cd09f25586ed7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5d8131470794f49a18e6a2483c9aedb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24caf0f25e724ab5874901575a9dff4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4450dea65a1a407db95aa762eb3ab97d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f668f3ea91b4a82ac1167c554f4554f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "461ae64db411441da7f731bb4522b75f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.013833,
          "end_time": "2021-08-23T18:41:54.499802",
          "exception": false,
          "start_time": "2021-08-23T18:41:54.485969",
          "status": "completed"
        },
        "tags": [],
        "id": "7ef8cb08"
      },
      "source": [
        "* LM_Dataformat allows for retrieval of data by providing an iterator method \"stream_data\""
      ],
      "id": "7ef8cb08"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T18:41:54.533419Z",
          "iopub.status.busy": "2021-08-23T18:41:54.532761Z",
          "iopub.status.idle": "2021-08-23T18:41:54.554321Z",
          "shell.execute_reply": "2021-08-23T18:41:54.553490Z",
          "shell.execute_reply.started": "2021-08-23T18:29:10.385054Z"
        },
        "papermill": {
          "duration": 0.040021,
          "end_time": "2021-08-23T18:41:54.554485",
          "exception": false,
          "start_time": "2021-08-23T18:41:54.514464",
          "status": "completed"
        },
        "tags": [],
        "id": "335a648e"
      },
      "source": [
        "import lm_dataformat\n",
        "pile = lm_dataformat.Reader('../input/the-pile-train-00-dataset/the-eye.eu/public/AI/pile/train/29.jsonl.zst')"
      ],
      "id": "335a648e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.014116,
          "end_time": "2021-08-23T18:41:54.582910",
          "exception": false,
          "start_time": "2021-08-23T18:41:54.568794",
          "status": "completed"
        },
        "tags": [],
        "id": "138f5959"
      },
      "source": [
        "* Creating the array @param docs, which contains the first 10,000 documents of THE PILE dataset"
      ],
      "id": "138f5959"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T18:41:54.618909Z",
          "iopub.status.busy": "2021-08-23T18:41:54.618104Z",
          "iopub.status.idle": "2021-08-23T18:41:56.155820Z",
          "shell.execute_reply": "2021-08-23T18:41:56.156236Z",
          "shell.execute_reply.started": "2021-08-23T18:29:11.965263Z"
        },
        "papermill": {
          "duration": 1.559386,
          "end_time": "2021-08-23T18:41:56.156418",
          "exception": false,
          "start_time": "2021-08-23T18:41:54.597032",
          "status": "completed"
        },
        "tags": [],
        "id": "4aa3aea4",
        "outputId": "d8a82952-02bf-45e9-ca37-408dafd646cd"
      },
      "source": [
        "docsiter = iter(pile.stream_data())\n",
        "docs = []\n",
        "from tqdm import tqdm \n",
        "with tqdm(total=10000, position=0, leave=True) as pbar:\n",
        "    for i in range(10000):\n",
        "        docs.append(next(docsiter))\n",
        "        pbar.update()"
      ],
      "id": "4aa3aea4",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 6534.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T18:41:56.203511Z",
          "iopub.status.busy": "2021-08-23T18:41:56.202862Z",
          "iopub.status.idle": "2021-08-23T21:56:28.087250Z",
          "shell.execute_reply": "2021-08-23T21:56:28.086800Z",
          "shell.execute_reply.started": "2021-08-23T18:29:32.635976Z"
        },
        "papermill": {
          "duration": 11671.912301,
          "end_time": "2021-08-23T21:56:28.087379",
          "exception": false,
          "start_time": "2021-08-23T18:41:56.175078",
          "status": "completed"
        },
        "tags": [],
        "id": "98f039d8",
        "outputId": "034df19d-b3ff-4958-e7b4-b8d07b82ac72"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "acc = [[],[],[]]\n",
        "from sklearn.metrics import accuracy_score\n",
        "with tqdm(total=10000, position=0, leave=True) as pbar:\n",
        "    for idx in range(10000):\n",
        "        doc = docs[idx]\n",
        "        input_ids = tokenizer(doc, return_tensors=\"pt\").input_ids\n",
        "        \n",
        "        if(input_ids.shape[1] < 40):\n",
        "            acc[0].append(idx)\n",
        "            acc[1].append(input_ids.shape[1])\n",
        "            acc[2].append(np.nan) #Input tokens are less than 40, append nan as logit\n",
        "            continue\n",
        "        \n",
        "        length = 20 #Length of subsequent tokens, the tokens utilized to calculate number of correctly predicted tokens\n",
        "        \n",
        "        gen_tokens = model.generate(input_ids[:,:20].cuda(), do_sample=True, temperature=0.1,pad_token_id=50256,eos_token_id=50256,\n",
        "                                    min_length=20+length,max_length=40+length).cpu()[0] #Generating tokens from the model\n",
        "        \n",
        "        score = torch.sum(input_ids[0,20:length+20] == gen_tokens[20:length+20]).item() #Calculating the number of correctly predicted tokens \n",
        "        \n",
        "        \n",
        "        #Appending the document index, length of input tokens and the score to the logit array, @param acc\n",
        "        acc[0].append(idx)\n",
        "        acc[1].append(input_ids.shape[1])\n",
        "        acc[2].append(score)\n",
        "        \n",
        "        idx+=1 #Temporary index, keeps count of current iteration\n",
        "        pbar.update()"
      ],
      "id": "98f039d8",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 7/10000 [00:09<3:21:42,  1.21s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (8723 > 2048). Running this sequence through the model will result in indexing errors\n",
            " 99%|█████████▊| 9860/10000 [3:14:31<02:45,  1.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T21:56:33.674563Z",
          "iopub.status.busy": "2021-08-23T21:56:33.673777Z",
          "iopub.status.idle": "2021-08-23T21:56:33.772218Z",
          "shell.execute_reply": "2021-08-23T21:56:33.771276Z"
        },
        "papermill": {
          "duration": 2.648357,
          "end_time": "2021-08-23T21:56:33.772350",
          "exception": false,
          "start_time": "2021-08-23T21:56:31.123993",
          "status": "completed"
        },
        "tags": [],
        "id": "cb57605e",
        "outputId": "992db92e-334c-42e3-f962-186d175a9f23"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(acc,'data29.pkl') #Saving @param acc"
      ],
      "id": "cb57605e",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data29.pkl']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}