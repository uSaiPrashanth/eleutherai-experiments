{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12137.05527,
      "end_time": "2021-08-23T09:17:23.854644",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-08-23T05:55:06.799374",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "name": "gpt-1-3b-model without shuffling (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.008232,
          "end_time": "2021-08-23T05:55:13.021813",
          "exception": false,
          "start_time": "2021-08-23T05:55:13.013581",
          "status": "completed"
        },
        "tags": [],
        "id": "770052ca"
      },
      "source": [
        "# About This Notebook\n",
        "* This notebook evaluates the number of tokens generated by the model EleutherAI/gpt-neo-1.3B with The Pile data\n",
        "* This is the unshuffled version of the notebook.\n",
        "* The Evaluation is done by the following methodology\n",
        "\n",
        "* Select documents within THE PILE 00 dataset with more than or equal to 40 tokens, replace the skipped logits with np.nan\n",
        "* Utilize the first 20 tokens of each document as input to the model and use the subsequent 20 tokens to calculate the number of correctly predicted tokens\n",
        "* Correctly predicted tokens are found by comparing the tokens in range 20..40 of the input document with the tokens in range 20--40 of generated document\n",
        "* This data is stored in the array acc and saved in the file 'withoutshuffle.pkl'\n",
        "* The following file contains information of the score of the model based on first 10,000 documents of THE PILE \n",
        "* The input to this dataset was a [kaggle dataset](https://www.kaggle.com/usaiprashanth/the-pile-train-00) dataset with output in the following [kaggle dataset](https://www.kaggle.com/usaiprashanth/gptmodel-outputs)\n",
        "* The following notebook is from a [kaggle notebook](https://www.kaggle.com/usaiprashanth/gpt-1-3b-model?scriptVersionId=72761073)"
      ],
      "id": "770052ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:55:13.057450Z",
          "iopub.status.busy": "2021-08-23T05:55:13.047963Z",
          "iopub.status.idle": "2021-08-23T05:55:26.877125Z",
          "shell.execute_reply": "2021-08-23T05:55:26.876519Z",
          "shell.execute_reply.started": "2021-08-23T05:47:33.187469Z"
        },
        "papermill": {
          "duration": 13.847952,
          "end_time": "2021-08-23T05:55:26.877317",
          "exception": false,
          "start_time": "2021-08-23T05:55:13.029365",
          "status": "completed"
        },
        "tags": [],
        "id": "79cf2dd7",
        "outputId": "e5d6374f-4be4-478e-8770-0fc1a34b56bf"
      },
      "source": [
        "!pip install lm-dataformat #Library for easy retrieval of The pile data from jsonl.zstd files\n",
        "!pip install transformers #Library for easy interaction with gpt-neo-1.3B model"
      ],
      "id": "79cf2dd7",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Collecting lm-dataformat\n  Downloading lm_dataformat-0.0.19-py3-none-any.whl (5.4 kB)\nCollecting zstandard\n  Downloading zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n\u001b[K     |████████████████████████████████| 2.2 MB 4.4 MB/s \n\u001b[?25hCollecting jsonlines\n  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\nRequirement already satisfied: ujson in /opt/conda/lib/python3.7/site-packages (from lm-dataformat) (4.0.2)\nInstalling collected packages: zstandard, jsonlines, lm-dataformat\nSuccessfully installed jsonlines-2.0.0 lm-dataformat-0.0.19 zstandard-0.15.2\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.6.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.61.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\nRequirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.8)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.011905,
          "end_time": "2021-08-23T05:55:26.902322",
          "exception": false,
          "start_time": "2021-08-23T05:55:26.890417",
          "status": "completed"
        },
        "tags": [],
        "id": "ccfcf4e1"
      },
      "source": [
        "* Creating the @param model using Huggingface api"
      ],
      "id": "ccfcf4e1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:55:26.933243Z",
          "iopub.status.busy": "2021-08-23T05:55:26.930786Z",
          "iopub.status.idle": "2021-08-23T06:00:22.999426Z",
          "shell.execute_reply": "2021-08-23T06:00:22.998759Z",
          "shell.execute_reply.started": "2021-08-23T05:47:48.202617Z"
        },
        "papermill": {
          "duration": 296.085068,
          "end_time": "2021-08-23T06:00:22.999572",
          "exception": false,
          "start_time": "2021-08-23T05:55:26.914504",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "a42b112a3aab4fa39f021e57c867aa77",
            "32951e7c27244219876917346f41af26",
            "2ed9fe1a3c1c4012b9338b41c9e33aa5",
            "343237e6f68c459ba11f799353cadb50",
            "0fe48fbc544c40d5bed35045b42a9433",
            "97f552a873a34320b52313baac716185"
          ]
        },
        "id": "c52ac04e",
        "outputId": "fca9b06a-1b82-463b-e0c7-f1957a2926da"
      },
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "id": "c52ac04e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a42b112a3aab4fa39f021e57c867aa77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32951e7c27244219876917346f41af26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Downloading:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ed9fe1a3c1c4012b9338b41c9e33aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "343237e6f68c459ba11f799353cadb50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fe48fbc544c40d5bed35045b42a9433",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97f552a873a34320b52313baac716185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.013928,
          "end_time": "2021-08-23T06:00:23.027911",
          "exception": false,
          "start_time": "2021-08-23T06:00:23.013983",
          "status": "completed"
        },
        "tags": [],
        "id": "bdfa42b2"
      },
      "source": [
        "* LM_Dataformat allows for retrieval of data by providing an iterator method \"stream_data\""
      ],
      "id": "bdfa42b2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T06:00:23.059626Z",
          "iopub.status.busy": "2021-08-23T06:00:23.059022Z",
          "iopub.status.idle": "2021-08-23T06:00:23.081922Z",
          "shell.execute_reply": "2021-08-23T06:00:23.081473Z",
          "shell.execute_reply.started": "2021-08-23T05:54:09.326689Z"
        },
        "papermill": {
          "duration": 0.04028,
          "end_time": "2021-08-23T06:00:23.082029",
          "exception": false,
          "start_time": "2021-08-23T06:00:23.041749",
          "status": "completed"
        },
        "tags": [],
        "id": "feec62cd"
      },
      "source": [
        "import lm_dataformat\n",
        "pile = lm_dataformat.Reader('../input/the-pile-train-00-dataset/the-eye.eu/public/AI/pile/train/00.jsonl.zst')"
      ],
      "id": "feec62cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.01507,
          "end_time": "2021-08-23T06:00:23.111616",
          "exception": false,
          "start_time": "2021-08-23T06:00:23.096546",
          "status": "completed"
        },
        "tags": [],
        "id": "b92bf982"
      },
      "source": [
        "* Creating the array @param docs, which contains the first 10,000 documents of THE PILE dataset"
      ],
      "id": "b92bf982"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T06:00:23.147233Z",
          "iopub.status.busy": "2021-08-23T06:00:23.146684Z",
          "iopub.status.idle": "2021-08-23T06:00:24.480181Z",
          "shell.execute_reply": "2021-08-23T06:00:24.479608Z",
          "shell.execute_reply.started": "2021-08-23T05:54:09.361455Z"
        },
        "papermill": {
          "duration": 1.354701,
          "end_time": "2021-08-23T06:00:24.480304",
          "exception": false,
          "start_time": "2021-08-23T06:00:23.125603",
          "status": "completed"
        },
        "tags": [],
        "id": "ab08ad21",
        "outputId": "bc0f75e7-96b4-46b0-e94f-dbc7c759943c"
      },
      "source": [
        "docsiter = iter(pile.stream_data())\n",
        "docs = []\n",
        "from tqdm import tqdm \n",
        "with tqdm(total=10000, position=0, leave=True) as pbar:\n",
        "    for i in range(10000):\n",
        "        docs.append(next(docsiter))\n",
        "        pbar.update()"
      ],
      "id": "ab08ad21",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 10000/10000 [00:01<00:00, 7545.18it/s]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T06:00:24.520567Z",
          "iopub.status.busy": "2021-08-23T06:00:24.519891Z",
          "iopub.status.idle": "2021-08-23T06:00:24.522670Z",
          "shell.execute_reply": "2021-08-23T06:00:24.522248Z",
          "shell.execute_reply.started": "2021-08-23T05:54:10.110051Z"
        },
        "papermill": {
          "duration": 0.024799,
          "end_time": "2021-08-23T06:00:24.522772",
          "exception": false,
          "start_time": "2021-08-23T06:00:24.497973",
          "status": "completed"
        },
        "tags": [],
        "id": "0f74bd58"
      },
      "source": [
        "documentidx = list(range(10000))"
      ],
      "id": "0f74bd58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T06:00:24.567249Z",
          "iopub.status.busy": "2021-08-23T06:00:24.566674Z",
          "iopub.status.idle": "2021-08-23T09:17:12.730396Z",
          "shell.execute_reply": "2021-08-23T09:17:12.730768Z",
          "shell.execute_reply.started": "2021-08-23T05:54:10.117376Z"
        },
        "papermill": {
          "duration": 11808.190555,
          "end_time": "2021-08-23T09:17:12.730935",
          "exception": false,
          "start_time": "2021-08-23T06:00:24.540380",
          "status": "completed"
        },
        "tags": [],
        "id": "b5fb86a6",
        "outputId": "72a7be1d-b067-470b-ba7f-aaad28cd14b7"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "acc = [[],[],[]]\n",
        "from sklearn.metrics import accuracy_score\n",
        "with tqdm(total=10000, position=0, leave=True) as pbar:\n",
        "    for idx in range(10000):\n",
        "        doc = docs[documentidx[idx]]\n",
        "        input_ids = tokenizer(doc, return_tensors=\"pt\").input_ids\n",
        "        \n",
        "        if(input_ids.shape[1] < 40):\n",
        "            acc[0].append(documentidx[idx])\n",
        "            acc[1].append(input_ids.shape[1])\n",
        "            acc[2].append(np.nan) #Input tokens are less than 40, append nan as logit\n",
        "            continue\n",
        "        \n",
        "        length = 20 #Length of subsequent tokens, the tokens utilized to calculate number of correctly predicted tokens\n",
        "        \n",
        "        gen_tokens = model.generate(input_ids[:,:20].cuda(), do_sample=True, temperature=0.1,pad_token_id=50256,eos_token_id=50256,\n",
        "                                    min_length=20+length,max_length=40+length).cpu()[0] #Generating tokens from the model\n",
        "        \n",
        "        score = torch.sum(input_ids[0,20:length+20] == gen_tokens[20:length+20]).item() #Calculating the number of correctly predicted tokens \n",
        "        \n",
        "        \n",
        "        #Appending the document index, length of input tokens and the score to the logit array, @param acc\n",
        "        acc[0].append(documentidx[idx])\n",
        "        acc[1].append(input_ids.shape[1])\n",
        "        acc[2].append(score)\n",
        "        \n",
        "        idx+=1 #Temporary index, keeps count of current iteration\n",
        "        pbar.update()"
      ],
      "id": "b5fb86a6",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "  0%|          | 0/10000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3180 > 2048). Running this sequence through the model will result in indexing errors\n 99%|█████████▉| 9875/10000 [3:16:47<02:29,  1.20s/it]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T09:17:17.895477Z",
          "iopub.status.busy": "2021-08-23T09:17:17.894920Z",
          "iopub.status.idle": "2021-08-23T09:17:17.993413Z",
          "shell.execute_reply": "2021-08-23T09:17:17.992836Z"
        },
        "papermill": {
          "duration": 2.652782,
          "end_time": "2021-08-23T09:17:17.993604",
          "exception": false,
          "start_time": "2021-08-23T09:17:15.340822",
          "status": "completed"
        },
        "tags": [],
        "id": "81719821",
        "outputId": "0418d0e1-cfe1-4858-ca9f-fdc4e1dbec1a"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(acc,'withoutshuffle.pkl') #Saving @param acc"
      ],
      "id": "81719821",
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['withoutshuffle.pkl']"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
