{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12064.481931,
      "end_time": "2021-08-23T09:06:23.590790",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-08-23T05:45:19.108859",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "name": "gpt-1-3b-model-with-shuffling.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.008403,
          "end_time": "2021-08-23T05:45:25.619189",
          "exception": false,
          "start_time": "2021-08-23T05:45:25.610786",
          "status": "completed"
        },
        "tags": [],
        "id": "002afa3a"
      },
      "source": [
        "# About This Notebook\n",
        "* This notebook evaluates the number of tokens generated by the model EleutherAI/gpt-neo-1.3B with The Pile data\n",
        "* This is the shuffled version of the notebook. The data has been shuffled with respect to position in the document (at document level)\n",
        "* The Evaluation is done by the following methodology\n",
        "\n",
        "* Select documents within THE PILE 00 dataset with more than or equal to 40 tokens, replace the skipped logits with np.nan\n",
        "* Utilize the first 20 tokens of each document as input to the model and use the subsequent 20 tokens to calculate the number of correctly predicted tokens\n",
        "* Correctly predicted tokens are found by comparing the tokens in range 20..40 of the input document with the tokens in range 20--40 of generated document\n",
        "* This data is stored in the array acc and saved in the file 'withshuffle.pkl'\n",
        "* The input to this dataset was a [kaggle dataset](https://www.kaggle.com/usaiprashanth/the-pile-train-00-dataset) dataset with output in the following [kaggle dataset](https://www.kaggle.com/usaiprashanth/gptmodel-outputs)\n",
        "* The following notebook is from a [kaggle notebook](https://www.kaggle.com/usaiprashanth/gpt-1-3b-model?scriptVersionId=72761073)"
      ],
      "id": "002afa3a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:45:25.655610Z",
          "iopub.status.busy": "2021-08-23T05:45:25.653529Z",
          "iopub.status.idle": "2021-08-23T05:45:40.577844Z",
          "shell.execute_reply": "2021-08-23T05:45:40.577178Z",
          "shell.execute_reply.started": "2021-08-23T05:30:15.359384Z"
        },
        "papermill": {
          "duration": 14.951185,
          "end_time": "2021-08-23T05:45:40.577988",
          "exception": false,
          "start_time": "2021-08-23T05:45:25.626803",
          "status": "completed"
        },
        "tags": [],
        "id": "8b1820e6",
        "outputId": "47c1d745-14d0-42ca-a191-b8bf9c6575ac"
      },
      "source": [
        "!pip install lm-dataformat #Library for easy retrieval of The pile data from jsonl.zstd files\n",
        "!pip install transformers #Library for easy interaction with gpt-neo-1.3B model"
      ],
      "id": "8b1820e6",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lm-dataformat\r\n",
            "  Downloading lm_dataformat-0.0.19-py3-none-any.whl (5.4 kB)\r\n",
            "Collecting zstandard\r\n",
            "  Downloading zstandard-0.15.2-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\r\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 605 kB/s \r\n",
            "\u001b[?25hRequirement already satisfied: ujson in /opt/conda/lib/python3.7/site-packages (from lm-dataformat) (4.0.2)\r\n",
            "Collecting jsonlines\r\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\r\n",
            "Installing collected packages: zstandard, jsonlines, lm-dataformat\r\n",
            "Successfully installed jsonlines-2.0.0 lm-dataformat-0.0.19 zstandard-0.15.2\r\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.6.1)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.61.1)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\r\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\r\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.8)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\r\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\r\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\r\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\r\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\r\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\r\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\r\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\r\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\r\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024885,
          "end_time": "2021-08-23T05:45:40.623900",
          "exception": false,
          "start_time": "2021-08-23T05:45:40.599015",
          "status": "completed"
        },
        "tags": [],
        "id": "fefdd3d5"
      },
      "source": [
        "* Creating the @param model using Huggingface api"
      ],
      "id": "fefdd3d5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:45:40.679428Z",
          "iopub.status.busy": "2021-08-23T05:45:40.678583Z",
          "iopub.status.idle": "2021-08-23T05:49:30.008858Z",
          "shell.execute_reply": "2021-08-23T05:49:30.007961Z",
          "shell.execute_reply.started": "2021-08-23T05:30:29.898386Z"
        },
        "papermill": {
          "duration": 229.360923,
          "end_time": "2021-08-23T05:49:30.009008",
          "exception": false,
          "start_time": "2021-08-23T05:45:40.648085",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "0313e8c2f22f40fc9de907ea97c2dbcb",
            "7727d25976fa4b97ba3da47ebc8989ed",
            "8c772e6385014fe29bf14b2df5d0259d",
            "e0429295550441a38ecec24a3571f17d",
            "0fe3d36e2f934edd892642a289947928",
            "bdedfea0ed004519a773fa00f6286d14"
          ]
        },
        "id": "56091d09",
        "outputId": "ca931fb6-e89f-4ecb-ef8a-2625abb4791b"
      },
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").cuda()\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "id": "56091d09",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0313e8c2f22f40fc9de907ea97c2dbcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7727d25976fa4b97ba3da47ebc8989ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c772e6385014fe29bf14b2df5d0259d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0429295550441a38ecec24a3571f17d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fe3d36e2f934edd892642a289947928",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdedfea0ed004519a773fa00f6286d14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.016165,
          "end_time": "2021-08-23T05:49:30.041623",
          "exception": false,
          "start_time": "2021-08-23T05:49:30.025458",
          "status": "completed"
        },
        "tags": [],
        "id": "d1732bca"
      },
      "source": [
        "* LM_Dataformat allows for retrieval of data by providing an iterator method \"stream_data\""
      ],
      "id": "d1732bca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:49:30.078954Z",
          "iopub.status.busy": "2021-08-23T05:49:30.078169Z",
          "iopub.status.idle": "2021-08-23T05:49:30.099919Z",
          "shell.execute_reply": "2021-08-23T05:49:30.099447Z",
          "shell.execute_reply.started": "2021-08-23T05:31:54.064239Z"
        },
        "papermill": {
          "duration": 0.041895,
          "end_time": "2021-08-23T05:49:30.100031",
          "exception": false,
          "start_time": "2021-08-23T05:49:30.058136",
          "status": "completed"
        },
        "tags": [],
        "id": "cc228567"
      },
      "source": [
        "import lm_dataformat\n",
        "pile = lm_dataformat.Reader('../input/the-pile-train-00-dataset/the-eye.eu/public/AI/pile/train/00.jsonl.zst')"
      ],
      "id": "cc228567",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015877,
          "end_time": "2021-08-23T05:49:30.132619",
          "exception": false,
          "start_time": "2021-08-23T05:49:30.116742",
          "status": "completed"
        },
        "tags": [],
        "id": "88640b47"
      },
      "source": [
        "* Creating the array @param docs, which contains the first 10,000 documents of THE PILE dataset"
      ],
      "id": "88640b47"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:49:30.173629Z",
          "iopub.status.busy": "2021-08-23T05:49:30.173086Z",
          "iopub.status.idle": "2021-08-23T05:49:30.960767Z",
          "shell.execute_reply": "2021-08-23T05:49:30.959338Z",
          "shell.execute_reply.started": "2021-08-23T05:31:54.110460Z"
        },
        "papermill": {
          "duration": 0.812436,
          "end_time": "2021-08-23T05:49:30.960981",
          "exception": false,
          "start_time": "2021-08-23T05:49:30.148545",
          "status": "completed"
        },
        "tags": [],
        "id": "07c1bb71",
        "outputId": "8e666533-054b-48b3-eaca-e627eaefb10a"
      },
      "source": [
        "docsiter = iter(pile.stream_data())\n",
        "docs = []\n",
        "from tqdm import tqdm \n",
        "with tqdm(total=10000, position=0, leave=True) as pbar:\n",
        "    for i in range(10000):\n",
        "        docs.append(next(docsiter))\n",
        "        pbar.update()"
      ],
      "id": "07c1bb71",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 12811.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.018485,
          "end_time": "2021-08-23T05:49:30.998694",
          "exception": false,
          "start_time": "2021-08-23T05:49:30.980209",
          "status": "completed"
        },
        "tags": [],
        "id": "b239db85"
      },
      "source": [
        "* Shuffling first 10,000 records by shuffling a position pointer array"
      ],
      "id": "b239db85"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:49:31.048024Z",
          "iopub.status.busy": "2021-08-23T05:49:31.047415Z",
          "iopub.status.idle": "2021-08-23T05:49:31.050172Z",
          "shell.execute_reply": "2021-08-23T05:49:31.050553Z",
          "shell.execute_reply.started": "2021-08-23T05:31:55.541403Z"
        },
        "papermill": {
          "duration": 0.03353,
          "end_time": "2021-08-23T05:49:31.050692",
          "exception": false,
          "start_time": "2021-08-23T05:49:31.017162",
          "status": "completed"
        },
        "tags": [],
        "id": "968a15c6"
      },
      "source": [
        "import random\n",
        "documentidx = list(range(10000))\n",
        "random.shuffle(documentidx)"
      ],
      "id": "968a15c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T05:49:31.097525Z",
          "iopub.status.busy": "2021-08-23T05:49:31.096906Z",
          "iopub.status.idle": "2021-08-23T09:06:12.601902Z",
          "shell.execute_reply": "2021-08-23T09:06:12.601467Z",
          "shell.execute_reply.started": "2021-08-23T05:36:28.825774Z"
        },
        "papermill": {
          "duration": 11801.533108,
          "end_time": "2021-08-23T09:06:12.602037",
          "exception": false,
          "start_time": "2021-08-23T05:49:31.068929",
          "status": "completed"
        },
        "tags": [],
        "id": "09e115d3",
        "outputId": "581df689-c2bd-41f0-b004-6282b12e7f65"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "acc = [[],[],[]]\n",
        "from sklearn.metrics import accuracy_score\n",
        "with tqdm(total=10000, position=0, leave=True) as pbar:\n",
        "    for idx in range(10000):\n",
        "        doc = docs[documentidx[idx]]\n",
        "        input_ids = tokenizer(doc, return_tensors=\"pt\").input_ids\n",
        "        \n",
        "        if(input_ids.shape[1] < 40):\n",
        "            acc[0].append(documentidx[idx])\n",
        "            acc[1].append(input_ids.shape[1])\n",
        "            acc[2].append(np.nan) #Input tokens are less than 40, append nan as logit\n",
        "            continue\n",
        "        \n",
        "        length = 20 #Length of subsequent tokens, the tokens utilized to calculate number of correctly predicted tokens\n",
        "        \n",
        "        gen_tokens = model.generate(input_ids[:,:20].cuda(), do_sample=True, temperature=0.1,pad_token_id=50256,eos_token_id=50256,\n",
        "                                    min_length=20+length,max_length=40+length).cpu()[0] #Generating tokens from the model\n",
        "        \n",
        "        score = torch.sum(input_ids[0,20:length+20] == gen_tokens[20:length+20]).item() #Calculating the number of correctly predicted tokens \n",
        "        \n",
        "        \n",
        "        #Appending the document index, length of input tokens and the score to the logit array, @param acc\n",
        "        acc[0].append(documentidx[idx])\n",
        "        acc[1].append(input_ids.shape[1])\n",
        "        acc[2].append(score)\n",
        "        \n",
        "        idx+=1 #Temporary index, keeps count of current iteration\n",
        "        pbar.update()"
      ],
      "id": "09e115d3",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/10000 [00:02<5:51:38,  2.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (989184 > 2048). Running this sequence through the model will result in indexing errors\n",
            " 99%|█████████▉| 9875/10000 [3:16:40<02:29,  1.20s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-23T09:06:17.955383Z",
          "iopub.status.busy": "2021-08-23T09:06:17.954572Z",
          "iopub.status.idle": "2021-08-23T09:06:18.038162Z",
          "shell.execute_reply": "2021-08-23T09:06:18.037755Z"
        },
        "papermill": {
          "duration": 2.634187,
          "end_time": "2021-08-23T09:06:18.038281",
          "exception": false,
          "start_time": "2021-08-23T09:06:15.404094",
          "status": "completed"
        },
        "tags": [],
        "id": "b494942d",
        "outputId": "e560ae68-3a7d-4ffb-aa69-37a094b806bb"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(acc,'withshuffle.pkl') #Saving @param acc"
      ],
      "id": "b494942d",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['withshuffle.pkl']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}